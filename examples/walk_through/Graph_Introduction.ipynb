{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk-through\n",
    "============\n",
    "\n",
    "This walk-through guides users through several key concepts for using the nervana graph. The corresponding jupyter notebook is found [here](https://github.com/NervanaSystems/ngraph/blob/master/examples/walk_through/Graph_Introduction.ipynb).\n",
    "\n",
    "Let's begin with a very simple example: computing ``x+1`` for several values of ``x`` using the ``ngraph``\n",
    "API.  We should think of the computation as being invoked from the *host*, but possibly taking place\n",
    "somewhere else, which we will refer to as *the device.*\n",
    "\n",
    "The nervana graph currently uses a compilation model. Users first define the computations by building a graph of operations, then they are compiled and run. In the future, we plan an even more compiler-like approach, where an executable is produced that can later be run on various platforms, in addition to an interactive version.\n",
    "\n",
    "Our first program will use ngraph to compute ``x+1`` for each ``x`` provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The x+1 program\n",
    "---------------\n",
    "\n",
    "The complete program, which we will walk through, is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from contextlib import closing\n",
    "import neon as ng\n",
    "import neon.transformers as ngt\n",
    "\n",
    "# Build the graph\n",
    "x = ng.placeholder(axes=())\n",
    "x_plus_one = x + 1\n",
    "\n",
    "# Select a transformer\n",
    "with closing(ngt.make_transformer()) as transformer:\n",
    "\n",
    "    # Define a computation\n",
    "    plus_one = transformer.computation(x_plus_one, x)\n",
    "\n",
    "    # Run the computation\n",
    "    for i in range(5):\n",
    "        print(plus_one(i)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by importing ``ngraph``, the Python module for graph construction, and ``ngraph.transformers``, the module for transformer operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import neon as ng\n",
    "import neon.transformers as ngt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a computational graph, which we refer to as ngraph, for the computation.  Following TensorFlow terminology, we use ``placeholder`` to define a port for transferring tensors between the host and the device. ``Axes`` are used to tell the graph the tensor shape. In this example, ``x`` is a scalar so the axes are empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = ng.placeholder(axes=())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x can be thought as a dummy node of the ngraph, providing an entry point for data into the computational graph. The ``ngraph`` graph construction API uses functions to build a graph of ``Op`` objects, the ngraph. Each function may add operations to the ngraph, and will return an ``Op`` that represents the computation. Here below, using implicitly ngraph as it will be made evident at the next step, we are adding an ``Op`` to the ngraph that takes as input the variable tensor x just defined, and the constant number 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_plus_one = x + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit of behind the scenes magic occurs with the Python number ``1`` in the expression above, which is not an ``Op``. When an argument to a graph constructor is not an ``Op``, nervana graph will attempt to convert it to an ``Op`` using ``ng.constant``, the graph function for creating a constant.  \n\n",
    "Thus, what it is really happening (when we are defining x_plus_one as above) is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_plus_one = ng.add(x, ng.constant(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about the Op hierarchy please visit: https://ngraph.nervanasys.com/docs/latest/building_graphs.html <br>\n",
    "<br>At this point, our computational graph has been defined with only one function to compute represented by x_plus_one. Once the ngraph is defined, we can compile it with a *transformer*.  Here we use ``make_transformer`` to make a default transformer.  We tell the transformer the function to compute, ``x_plus_one``, and the associated input parameters, only ``x`` in our example. The constant needs not to be repeated here, as it is part of the definition of the function to compute. The current default transformer uses NumPy for execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select a transformer\n",
    "with closing(ngt.make_transformer()) as transformer:\n",
    "\n",
    "    # Define a computation\n",
    "    plus_one = transformer.computation(x_plus_one, x)\n",
    "    \n",
    "    # Run the computation\n",
    "    for i in range(5):\n",
    "        print(plus_one(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time the transformer executes a computation, the ngraph is analyzed and compiled, and storage is allocated and initialized on the device. Once compiled, the computations are callable Python objects residing on the host. On each call to ``plus_one`` the value of ``x`` is copied to the device, 1 is added, and then the result is copied\n",
    "back from the device to the host."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Compiled x + 1 Program\n",
    "The compiled code, to be executed on the device, can be examined (currently located in ``/tmp`` folder) to view the runtime device model. Here we show the code with some clarifying comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self):\n",
    "        self.a_AssignableTensorOp_0_0 = None\n",
    "        self.a_AssignableTensorOp_0_0_v_AssignableTensorOp_0_0_ = None\n",
    "        self.a_AssignableTensorOp_1_0 = None\n",
    "        self.a_AssignableTensorOp_1_0_v_AssignableTensorOp_1_0_ = None\n",
    "        self.a_AddZeroDim_0_0 = None\n",
    "        self.a_AddZeroDim_0_0_v_AddZeroDim_0_0_ = None\n",
    "        self.be = NervanaObject.be\n",
    "\n",
    "    def alloc_a_AssignableTensorOp_0_0(self):\n",
    "        self.update_a_AssignableTensorOp_0_0(np.empty(1, dtype=np.dtype('float32')))\n",
    "\n",
    "    def update_a_AssignableTensorOp_0_0(self, buffer):\n",
    "        self.a_AssignableTensorOp_0_0 = buffer\n",
    "        self.a_AssignableTensorOp_0_0_v_AssignableTensorOp_0_0_ = np.ndarray(shape=(), dtype=np.float32,\n",
    "            buffer=buffer, offset=0, strides=())\n",
    "\n",
    "    def alloc_a_AssignableTensorOp_1_0(self):\n",
    "        self.update_a_AssignableTensorOp_1_0(np.empty(1, dtype=np.dtype('float32')))\n",
    "\n",
    "    def update_a_AssignableTensorOp_1_0(self, buffer):\n",
    "        self.a_AssignableTensorOp_1_0 = buffer\n",
    "        self.a_AssignableTensorOp_1_0_v_AssignableTensorOp_1_0_ = np.ndarray(shape=(), dtype=np.float32,\n",
    "            buffer=buffer, offset=0, strides=())\n",
    "\n",
    "    def alloc_a_AddZeroDim_0_0(self):\n",
    "        self.update_a_AddZeroDim_0_0(np.empty(1, dtype=np.dtype('float32')))\n",
    "\n",
    "    def update_a_AddZeroDim_0_0(self, buffer):\n",
    "        self.a_AddZeroDim_0_0 = buffer\n",
    "        self.a_AddZeroDim_0_0_v_AddZeroDim_0_0_ = np.ndarray(shape=(), dtype=np.float32,\n",
    "            buffer=buffer, offset=0, strides=())\n",
    "\n",
    "    def allocate(self):\n",
    "        self.alloc_a_AssignableTensorOp_0_0()\n",
    "        self.alloc_a_AssignableTensorOp_1_0()\n",
    "        self.alloc_a_AddZeroDim_0_0()\n",
    "\n",
    "    def Computation_0(self):\n",
    "        np.add(self.a_AssignableTensorOp_0_0_v_AssignableTensorOp_0_0_, \n",
    "               self.a_AssignableTensorOp_1_0_v_AssignableTensorOp_1_0_, \n",
    "               out=self.a_AddZeroDim_0_0_v_AddZeroDim_0_0_)\n",
    "\n",
    "    def init(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors have two components: \n",
    "- storage for their elements (using the convention ``a_`` for the allocated storage of a tensor) and \n",
    "- views of that storage (denoted as ``a_...v_``).\n",
    "\n",
    "The ``alloc_`` methods allocate storage and then create the views of the storage that will be needed.  The view creation is separated from the allocation because storage may be allocated in multiple ways.\n",
    "\n",
    "Each allocated storage can also be initialized to, for example, random Gaussian variables. In this example, there are no initializations, so the method ``init``, which performs the one-time device\n",
    "initialization, is empty.  Constants, such as 1, are copied to the device as part of the allocation process.\n",
    "\n",
    "The method ``Computation_0`` handles the ``plus_one`` computation.  Clearly this is not the optimal way to add 1 to a scalar,\n",
    "so let's look at a more complex example next in the Logistic Regression walk-through."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
